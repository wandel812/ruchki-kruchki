{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd \r\n",
    "from pathlib import Path\r\n",
    "import glob \r\n",
    "import cv2\r\n",
    "import mediapipe as mp\r\n",
    "\r\n",
    "mp_drawing = mp.solutions.drawing_utils\r\n",
    "mp_hands = mp.solutions.hands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_from_images(img_paths, labels, save_dir_path=None):\r\n",
    "    df = pd.DataFrame(columns=labels)\r\n",
    "    skipped_img_count = 0\r\n",
    "\r\n",
    "    with mp_hands.Hands(\r\n",
    "        static_image_mode=True,\r\n",
    "        max_num_hands=1,\r\n",
    "        min_detection_confidence=0.5) as hands:\r\n",
    "        for idx, img_path in enumerate(img_paths):\r\n",
    "            multi_hand_landmarks = extract_multihand_landmarks(img_path, hands)\r\n",
    "\r\n",
    "            if not multi_hand_landmarks:\r\n",
    "                skipped_img_count += 1\r\n",
    "                continue\r\n",
    "            \r\n",
    "            first_hand_landmarks = multi_hand_landmarks[0]\r\n",
    "            df_series = fill_df_series(first_hand_landmarks, df.columns)\r\n",
    "            df = df.append(df_series, ignore_index=True)\r\n",
    "\r\n",
    "            if save_dir_path is not None:\r\n",
    "                save_annotated_image(img_path, save_dir_path, first_hand_landmarks)\r\n",
    "\r\n",
    "    print(f\"skipped images count f{skipped_img_count}\")    \r\n",
    "    return df\r\n",
    "\r\n",
    "def fill_df_series(hand_landmarks, labels):\r\n",
    "    df_row = []\r\n",
    "    for finger_part in hand_landmarks.landmark:\r\n",
    "        df_row.extend([finger_part.x, finger_part.y])\r\n",
    "    return pd.Series(df_row, index=labels)\r\n",
    "\r\n",
    "def extract_multihand_landmarks(hands, image_path):\r\n",
    "    image = cv2.flip(cv2.imread(image_path), 1)\r\n",
    "    return hands.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\r\n",
    "\r\n",
    "def save_annotated_image(img_path, save_dir_path, hand_landmarks):\r\n",
    "    annotated_image = cv2.imread(img_path)\r\n",
    "    save_dir_path.mkdir(parents=True, exist_ok=True)\r\n",
    "    mp_drawing.draw_landmarks(\r\n",
    "      annotated_image, hand_landmarks, mp_hands.HAND_CONNECTIONS)\r\n",
    "    cv2.imwrite(str(save_dir_path / Path(img_path).name), \r\n",
    "                cv2.flip(annotated_image, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 img skipped\n",
      "1 img skipped\n",
      "2 img skipped\n",
      "3 img skipped\n",
      "4 img skipped\n",
      "6 img skipped\n",
      "7 img skipped\n",
      "8 img skipped\n",
      "9 img skipped\n",
      "10 img skipped\n",
      "11 img skipped\n",
      "12 img skipped\n",
      "13 img skipped\n",
      "14 img skipped\n",
      "15 img skipped\n",
      "16 img skipped\n",
      "17 img skipped\n",
      "20 img skipped\n",
      "21 img skipped\n",
      "22 img skipped\n",
      "23 img skipped\n",
      "24 img skipped\n",
      "25 img skipped\n",
      "26 img skipped\n",
      "27 img skipped\n",
      "28 img skipped\n",
      "29 img skipped\n",
      "30 img skipped\n",
      "31 img skipped\n",
      "32 img skipped\n",
      "33 img skipped\n",
      "34 img skipped\n",
      "35 img skipped\n",
      "36 img skipped\n",
      "37 img skipped\n",
      "38 img skipped\n",
      "39 img skipped\n",
      "40 img skipped\n",
      "41 img skipped\n",
      "42 img skipped\n",
      "43 img skipped\n",
      "44 img skipped\n",
      "45 img skipped\n",
      "46 img skipped\n",
      "47 img skipped\n",
      "49 img skipped\n",
      "50 img skipped\n",
      "51 img skipped\n",
      "52 img skipped\n",
      "53 img skipped\n",
      "55 img skipped\n",
      "56 img skipped\n",
      "57 img skipped\n",
      "58 img skipped\n",
      "59 img skipped\n",
      "60 img skipped\n",
      "61 img skipped\n",
      "62 img skipped\n",
      "63 img skipped\n",
      "64 img skipped\n",
      "65 img skipped\n",
      "66 img skipped\n",
      "67 img skipped\n",
      "68 img skipped\n",
      "69 img skipped\n",
      "70 img skipped\n",
      "71 img skipped\n",
      "72 img skipped\n",
      "73 img skipped\n",
      "74 img skipped\n",
      "75 img skipped\n",
      "76 img skipped\n",
      "77 img skipped\n",
      "78 img skipped\n",
      "79 img skipped\n",
      "80 img skipped\n",
      "81 img skipped\n",
      "82 img skipped\n",
      "83 img skipped\n",
      "84 img skipped\n",
      "85 img skipped\n",
      "86 img skipped\n",
      "87 img skipped\n",
      "88 img skipped\n",
      "89 img skipped\n",
      "90 img skipped\n",
      "91 img skipped\n",
      "92 img skipped\n",
      "94 img skipped\n",
      "95 img skipped\n",
      "96 img skipped\n",
      "97 img skipped\n",
      "98 img skipped\n",
      "99 img skipped\n"
     ]
    }
   ],
   "source": [
    "feat_labels = [\r\n",
    "    'WRIST_X', 'WRIST_Y', \r\n",
    "    'THUMB_CMC_X', 'THUMB_CMC_Y',\r\n",
    "    'THUMB_MCP_X', 'THUMB_MCP_X',\r\n",
    "    'THUMB_IP_X', 'THUMB_IP_X',\r\n",
    "    'THUMB_TIP_X', 'THUMB_TIP_X',\r\n",
    "    'INDEX_FINGER_MCP_X', 'INDEX_FINGER_MCP_Y',\r\n",
    "    'INDEX_FINGER_PIP_X', 'INDEX_FINGER_PIP_Y',\r\n",
    "    'INDEX_FINGER_DIP_X', 'INDEX_FINGER_DIP_Y',\r\n",
    "    'INDEX_FINGER_TIP_X', 'INDEX_FINGER_TIP_Y',\r\n",
    "    'MIDDLE_FINGER_MCP_X', 'MIDDLE_FINGER_MCP_Y',\r\n",
    "    'MIDDLE_FINGER_PIP_X', 'MIDDLE_FINGER_PIP_Y',\r\n",
    "    'MIDDLE_FINGER_DIP_X', 'MIDDLE_FINGER_DIP_Y',\r\n",
    "    'MIDDLE_FINGER_TIP_X', 'MIDDLE_FINGER_TIP_Y',\r\n",
    "    'RING_FINGER_MCP_X', 'RING_FINGER_MCP_Y',\r\n",
    "    'RING_FINGER_PIP_X', 'RING_FINGER_PIP_Y',\r\n",
    "    'RING_FINGER_DIP_X', 'RING_FINGER_DIP_Y',\r\n",
    "    'RING_FINGER_TIP_X', 'RING_FINGER_TIP_Y',\r\n",
    "    'PINKY_MCP_X', 'PINKY_MCP_Y',\r\n",
    "    'PINKY_PIP_X', 'PINKY_PIP_Y',\r\n",
    "    'PINKY_DIP_X', 'PINKY_DIP_Y',\r\n",
    "    'PINKY_TIP_X', 'PINKY_TIP_Y']\r\n",
    "\r\n",
    "dataset_path = \"./input\"\r\n",
    "train_imgs = glob.glob('./input/train/*')\r\n",
    "test_imgs = glob.glob('./input/test/*')\r\n",
    "save_dir_path = Path('./output')\r\n",
    "df = extract_features_from_images(train_imgs[:100], feat_labels, save_dir_path)\r\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "26c71fa0b2a1877045fef87f8c36981d68abb2c7c715b271074d7603c5ae2e67"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}