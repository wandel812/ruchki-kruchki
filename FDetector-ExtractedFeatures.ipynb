{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd \r\n",
    "from pathlib import Path\r\n",
    "import glob \r\n",
    "import cv2\r\n",
    "import mediapipe as mp\r\n",
    "\r\n",
    "mp_drawing = mp.solutions.drawing_utils\r\n",
    "mp_hands = mp.solutions.hands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_from_images(img_paths, labels, save_dir_path=None):\r\n",
    "    df = pd.DataFrame(columns=labels)\r\n",
    "    skipped_img_count = 0\r\n",
    "\r\n",
    "    hands =  mp_hands.Hands(static_image_mode=True, \r\n",
    "                            max_num_hands=1, \r\n",
    "                            min_detection_confidence=0.5)\r\n",
    "\r\n",
    "    for idx, img_path in enumerate(img_paths):\r\n",
    "        multi_hand_landmarks = extract_multihand_landmarks(img_path, hands)\r\n",
    "\r\n",
    "        if not multi_hand_landmarks:\r\n",
    "            skipped_img_count += 1\r\n",
    "            continue\r\n",
    "        \r\n",
    "        first_hand_landmarks = multi_hand_landmarks[0]\r\n",
    "        df_series = fill_df_series(first_hand_landmarks, df.columns)\r\n",
    "        df = df.append(df_series, ignore_index=True)\r\n",
    "\r\n",
    "        if save_dir_path is not None:\r\n",
    "            save_annotated_image(img_path, save_dir_path, first_hand_landmarks)\r\n",
    "\r\n",
    "    print(f\"skipped images count f{skipped_img_count}\")    \r\n",
    "    return df\r\n",
    "\r\n",
    "def fill_df_series(hand_landmarks, labels):\r\n",
    "    df_row = []\r\n",
    "    for finger_part in hand_landmarks.landmark:\r\n",
    "        df_row.extend([finger_part.x, finger_part.y])\r\n",
    "    return pd.Series(df_row, index=labels)\r\n",
    "\r\n",
    "def extract_multihand_landmarks(hands, image_path):\r\n",
    "    image = cv2.flip(cv2.imread(image_path), 1)\r\n",
    "    return hands.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\r\n",
    "\r\n",
    "def save_annotated_image(img_path, save_dir_path, hand_landmarks):\r\n",
    "    annotated_image = cv2.imread(img_path)\r\n",
    "    save_dir_path.mkdir(parents=True, exist_ok=True)\r\n",
    "    mp_drawing.draw_landmarks(\r\n",
    "      annotated_image, hand_landmarks, mp_hands.HAND_CONNECTIONS)\r\n",
    "    cv2.imwrite(str(save_dir_path / Path(img_path).name), \r\n",
    "                annotated_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipped images count f0\n"
     ]
    }
   ],
   "source": [
    "feat_labels = [\r\n",
    "    'WRIST_X', 'WRIST_Y', \r\n",
    "    'THUMB_CMC_X', 'THUMB_CMC_Y',\r\n",
    "    'THUMB_MCP_X', 'THUMB_MCP_X',\r\n",
    "    'THUMB_IP_X', 'THUMB_IP_X',\r\n",
    "    'THUMB_TIP_X', 'THUMB_TIP_X',\r\n",
    "    'INDEX_FINGER_MCP_X', 'INDEX_FINGER_MCP_Y',\r\n",
    "    'INDEX_FINGER_PIP_X', 'INDEX_FINGER_PIP_Y',\r\n",
    "    'INDEX_FINGER_DIP_X', 'INDEX_FINGER_DIP_Y',\r\n",
    "    'INDEX_FINGER_TIP_X', 'INDEX_FINGER_TIP_Y',\r\n",
    "    'MIDDLE_FINGER_MCP_X', 'MIDDLE_FINGER_MCP_Y',\r\n",
    "    'MIDDLE_FINGER_PIP_X', 'MIDDLE_FINGER_PIP_Y',\r\n",
    "    'MIDDLE_FINGER_DIP_X', 'MIDDLE_FINGER_DIP_Y',\r\n",
    "    'MIDDLE_FINGER_TIP_X', 'MIDDLE_FINGER_TIP_Y',\r\n",
    "    'RING_FINGER_MCP_X', 'RING_FINGER_MCP_Y',\r\n",
    "    'RING_FINGER_PIP_X', 'RING_FINGER_PIP_Y',\r\n",
    "    'RING_FINGER_DIP_X', 'RING_FINGER_DIP_Y',\r\n",
    "    'RING_FINGER_TIP_X', 'RING_FINGER_TIP_Y',\r\n",
    "    'PINKY_MCP_X', 'PINKY_MCP_Y',\r\n",
    "    'PINKY_PIP_X', 'PINKY_PIP_Y',\r\n",
    "    'PINKY_DIP_X', 'PINKY_DIP_Y',\r\n",
    "    'PINKY_TIP_X', 'PINKY_TIP_Y']\r\n",
    "\r\n",
    "dataset_path = \"./input\"\r\n",
    "train_imgs = glob.glob('./input/train/*')\r\n",
    "test_imgs = glob.glob('./input/test/*')\r\n",
    "save_dir_path = Path('./output')\r\n",
    "df = extract_features_from_images(train_imgs[:100], feat_labels, save_dir_path)\r\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "26c71fa0b2a1877045fef87f8c36981d68abb2c7c715b271074d7603c5ae2e67"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}